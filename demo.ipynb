{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gZVXErI3ehK"
   },
   "source": [
    "# Color Mismatches in Stereoscopic Video: Real-World Dataset and Deep Correction Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaR_oXlq9b51"
   },
   "source": [
    "[Paper](https://arxiv.org/abs/2303.06657)\n",
    "|\n",
    "[Real-World Dataset](https://videoprocessing.ai/datasets/stereo-mismatch.html)\n",
    "|\n",
    "[WandB](https://wandb.ai/egorchistov/color-transfer)\n",
    "|\n",
    "[GitHub](https://github.com/egorchistov/color-transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmYESMW46xcG"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuxMWCBpy5dI"
   },
   "source": [
    "Clone this repo and install dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlxJtFJ6y6L6",
    "outputId": "7162b2d6-7c96-4379-af04-39abddb0d177"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/egorchistov/color-transfer.git\n",
    "%cd color-transfer\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1KxFtOZ3-X9"
   },
   "source": [
    "First load test stereopair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOTPFfq-36mY"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from skimage.util import img_as_float\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "gt = Image.open(\"graphics/0964_L.png\")\n",
    "reference = Image.open(\"graphics/0964_R.png\")\n",
    "\n",
    "target = F.adjust_hue(gt, hue_factor=0.5)\n",
    "\n",
    "target, gt, reference = img_as_float(target), img_as_float(gt), img_as_float(reference) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXfDcy9Bkr5U"
   },
   "source": [
    "Then visualize methods results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-LvRdoz2FvV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def plot_views(result):\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    difference = np.abs(rgb2gray(gt - result)).clip(0, 1)\n",
    "    difference /= difference.max()\n",
    "\n",
    "    for i, (image, label) in enumerate(zip(\n",
    "        [target, reference, result.clip(0, 1), difference],\n",
    "        [\"Target\", \"Reference\", \"Result\", \"Normalized Absolute Difference\"]\n",
    "    )):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        plt.title(label)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MII4UMAS0Iit"
   },
   "source": [
    "## Global Linear Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwgW35Lw7qTY"
   },
   "source": [
    "E. Reinhard, M. Ashikhmin, B. Gooch, and P. Shirley, “Color transfer\n",
    "between images,” *IEEE Computer Graphics and Applications*, vol. 21,\n",
    "pp. 34–41, 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "1vlUkQUM3LAT",
    "outputId": "0396b74d-76fa-4505-a8e5-525a55b47f2f"
   },
   "outputs": [],
   "source": [
    "from methods.linear import color_transfer_between_images as ct\n",
    "\n",
    "plot_views(ct(target, reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jshClc_O7-iu"
   },
   "source": [
    "X. Xiao and L. Ma, “Color transfer in correlated color space,” in\n",
    "*Proceedings of the 2006 ACM International Conference on Virtual Reality\n",
    "Continuum and Its Applications*, 2006, pp. 305–309."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "WrtCS3a8z8Z_",
    "outputId": "8476df59-023a-4024-8a8e-b7e33b4a2c9e"
   },
   "outputs": [],
   "source": [
    "from methods.linear import color_transfer_in_correlated_color_space as ct_ccs\n",
    "\n",
    "plot_views(ct_ccs(target, reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9Gk4gXk8Ipj"
   },
   "source": [
    "F. Pitié and A. Kokaram, “The linear monge-kantorovitch linear colour mapping for example-based colour transfer,” in *IET 4th European\n",
    "Conference on Visual Media Production*. IEE, 2007, pp. 1–9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "lBbxYsjp3S7k",
    "outputId": "1258e7b9-9ade-40b6-de8d-2d36b8deff7c"
   },
   "outputs": [],
   "source": [
    "from methods.linear import monge_kantorovitch_color_transfer as mkct\n",
    "\n",
    "plot_views(mkct(target, reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jf-Nu4HC0TeT"
   },
   "source": [
    "## Iterative Local Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8HhOYeJ8SOU"
   },
   "source": [
    "F. Pitié, A. Kokaram, and R. Dahyot, “Automated colour grading using colour distribution transfer,” *Computer Vision and Image Understanding*,\n",
    "vol. 107, no. 1–2, pp. 123–137, 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "_fxEpq6R4Mv2",
    "outputId": "67aaa1bd-84ef-4564-93ef-7bfb26bca727"
   },
   "outputs": [],
   "source": [
    "from methods.iterative import iterative_distribution_transfer as idt\n",
    "\n",
    "plot_views(idt(target, reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmSadXGJ8XXA"
   },
   "source": [
    "F. Pitié, A. Kokaram, and R. Dahyot, “Automated colour grading using colour distribution transfer,” *Computer Vision and Image Understanding*,\n",
    "vol. 107, no. 1–2, pp. 123–137, 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "0i1Qs82W0QFS",
    "outputId": "47e7252c-ebdb-487e-fb37-f9015e2859dc"
   },
   "outputs": [],
   "source": [
    "from methods.iterative import automated_color_grading as acg\n",
    "\n",
    "plot_views(acg(target, reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdYXmWdB4iJP"
   },
   "source": [
    "## Neural Network-Based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "8R_RK_Tz5ga7",
    "outputId": "5072aa22-407f-4916-e3e4-1fff2f7098be"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from wandb import Api\n",
    "from kornia import image_to_tensor, tensor_to_image\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "api = Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_39jEfx8vMr"
   },
   "source": [
    "S. Croci, C. Ozcinar, E. Zerman, R. Dudek, S. Knorr, and A. Smolic,\n",
    "“Deep color mismatch correction in stereoscopic 3d images,” in *2021\n",
    "IEEE International Conference on Image Processing (ICIP)*, 2021, pp.\n",
    "1749–1753."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "zy_p0Q0q4dik",
    "outputId": "7827db7d-aa75-4544-a0fc-b49ed259d22f"
   },
   "outputs": [],
   "source": [
    "from methods.dcmcs3di import DCMCS3DI\n",
    "\n",
    "artifact = api.artifact(\"egorchistov/color-transfer/model-y1mq1usg:v0\")\n",
    "artifact_dir = artifact.download()\n",
    "dcmcs3di = DCMCS3DI.load_from_checkpoint(os.path.join(artifact_dir, \"model.ckpt\"), map_location=device)\n",
    "dcmcs3di.to(device)\n",
    "dcmcs3di.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_dcmcs3di(target, reference):\n",
    "    target = image_to_tensor(target, keepdim=False).float().to(device)\n",
    "    reference = image_to_tensor(reference, keepdim=False).float().to(device)\n",
    "\n",
    "    height, width = target.shape[-2:]\n",
    "\n",
    "    # Without downscaling the evaluation will result in OOM\n",
    "    # In our comparison we used the GPUs with more memory and ran this method at full resolution\n",
    "    target = torch.nn.functional.interpolate(target, scale_factor=0.75, mode=\"bicubic\")\n",
    "    reference = torch.nn.functional.interpolate(reference, scale_factor=0.75, mode=\"bicubic\")\n",
    "\n",
    "    result, _ = dcmcs3di(target, reference, inference=True)\n",
    "\n",
    "    result = torch.nn.functional.interpolate(result, size=(height, width), mode=\"bicubic\")\n",
    "\n",
    "    return tensor_to_image(result)\n",
    "\n",
    "plot_views(run_dcmcs3di(target, reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TL03_qNg86UE"
   },
   "source": [
    "Our color-transfer method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "adi2av6j5os8",
    "outputId": "95f3d63a-f43f-4d80-a0ba-62bd1e3eea22"
   },
   "outputs": [],
   "source": [
    "from methods.dmsct import DMSCT\n",
    "\n",
    "artifact = api.artifact(\"egorchistov/color-transfer/model-86n1v9bd:v0\")\n",
    "artifact_dir = artifact.download()\n",
    "dmsct = DMSCT.load_from_checkpoint(os.path.join(artifact_dir, \"model.ckpt\"), map_location=device)\n",
    "dmsct.to(device)\n",
    "dmsct.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_dmsct(target, reference):\n",
    "    target = image_to_tensor(target, keepdim=False).float().to(device)\n",
    "    reference = image_to_tensor(reference, keepdim=False).float().to(device)\n",
    "\n",
    "    result = dmsct(target, reference)\n",
    "\n",
    "    return tensor_to_image(result)\n",
    "\n",
    "plot_views(run_dmsct(target, reference))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
